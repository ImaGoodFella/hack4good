{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98de5e0-fb85-46ba-a33f-744187c933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3233cf2f-ac37-4cb5-84c0-3fbc10826d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/rasteiger/datasets/hack4good/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e6a0dc-f2f0-444e-a23c-64083741bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataloader classs for images with corresponding labels such that pytorch can work with the data\n",
    "class CustomImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, csv_file, label_name, join_name, class_to_idx, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.label_name = label_name\n",
    "        self.join_name = join_name # column used to join img_dir and csv_file\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        # Integer class mapping: Labels classes -> [0, 1, ..., num(labels) - 1] for pytorch\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv_file.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, self.csv_file.iloc[idx][self.join_name])\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        # Load Label\n",
    "        label = self.class_to_idx[self.csv_file.iloc[idx][label_name]]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae68def1-085b-4e46-bf03-9589fd3861a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = data_path + \"images\"\n",
    "csv_path = data_path + \"labels.csv\"\n",
    "\n",
    "csv_file = pd.read_csv(csv_path)\n",
    "label_name = 'damage'\n",
    "join_name = 'filename'\n",
    "class_to_idx = {v:i for i, v in enumerate(csv_file[label_name].unique())} \n",
    "num_classes = len(list(class_to_idx.values()))\n",
    "size = 224\n",
    "\n",
    "# Perform image augmentation while training to artificially inflate dataset\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(size=(size, size), scale=(0.8, 1.0)),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.95),#, contrast=None, saturation=None),\n",
    "    torchvision.transforms.RandomRotation(degrees = (-15,+15)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Only resize for validation and test images\n",
    "val_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((size, size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 60% Train 20% Validate 20% Test split: https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "train_csv, val_csv, test_csv = np.split(csv_file.sample(frac=1), [int(.6*len(csv_file)), int(.8*len(csv_file))]) \n",
    "\n",
    "train_dataset = CustomImageDataset(img_dir=img_dir, csv_file=train_csv, label_name=label_name, join_name=join_name, transform=train_transforms, class_to_idx=class_to_idx)\n",
    "val_dataset = CustomImageDataset(img_dir=img_dir, csv_file=val_csv, label_name=label_name, join_name=join_name, transform=val_transforms, class_to_idx=class_to_idx)\n",
    "test_dataset = CustomImageDataset(img_dir=img_dir, csv_file=test_csv, label_name=label_name, join_name=join_name, transform=val_transforms, class_to_idx=class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a376ab-efa2-4516-8432-42d42ea409cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=64)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73437633-ec0d-4e81-bcb3-a45e0030d6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ConvNeXt(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
       "        )\n",
       "        (3): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
       "        )\n",
       "        (4): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
       "        )\n",
       "        (5): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
       "        )\n",
       "        (6): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
       "        )\n",
       "        (7): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
       "        )\n",
       "        (8): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=768, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.convnext_tiny(weights='DEFAULT')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.classifier[2] = torch.nn.Linear(768, num_classes, bias=True) # Since, we have only two classes, change the last layer\n",
    "model = torch.nn.DataParallel(model) # Ensure that we use all gpus available\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131db154-4f18-4c4c-80aa-1d2c8d130573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, data_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    tot_loss = 0\n",
    "    pred_labels, true_labels = [], []\n",
    "    \n",
    "    for i, (img, label) in enumerate(tqdm(train_loader)):\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(img)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        \n",
    "        pred_labels.append(pred.detach().cpu().numpy())\n",
    "        true_labels.append(label.detach().cpu().numpy())\n",
    "        \n",
    "        tot_loss += loss\n",
    "    \n",
    "    all_pred = np.concatenate(pred_labels)\n",
    "    all_true = np.concatenate(true_labels)\n",
    "    \n",
    "    f1 = f1_score(all_pred, all_true, average='macro')\n",
    "    accuracy = balanced_accuracy_score(all_pred, all_true)\n",
    "    tot_loss /= len(data_loader)\n",
    "    \n",
    "    line = '{:>8.4f} | {:>8.4f} | {:>5.4f}'.format(f1, accuracy, tot_loss.detach().cpu().numpy())\n",
    "    print(line, end=' \\t \\t ')\n",
    "    \n",
    "    return accuracy, tot_loss\n",
    "    \n",
    "def evaluate(model, data_loader, criterion, is_test=False):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    tot_loss = 0\n",
    "    pred_labels, true_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(tqdm(data_loader)):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "       \n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            pred = torch.argmax(output, dim=1)\n",
    "        \n",
    "            pred_labels.append(pred.detach().cpu().numpy())\n",
    "            true_labels.append(label.detach().cpu().numpy())\n",
    "\n",
    "            tot_loss += loss\n",
    "        \n",
    "    all_pred = np.concatenate(pred_labels)\n",
    "    all_true = np.concatenate(true_labels)\n",
    "    \n",
    "    f1 = f1_score(all_true, all_pred, average='macro')\n",
    "    accuracy = balanced_accuracy_score(all_true, all_pred)\n",
    "    precision = precision_score(all_true, all_pred, average='macro')\n",
    "    recall = recall_score(all_true, all_pred, average='macro')\n",
    "        \n",
    "    tot_loss /= len(data_loader)\n",
    "    \n",
    "    line = '{:>8.4f} | {:>8.4f} | {:>9.4f} | {:>6.4f} | {:>5.4f}'.format(f1, accuracy, precision, recall, tot_loss.detach().cpu().numpy())\n",
    "    print(line)\n",
    "    \n",
    "    return accuracy, tot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ecae78-4c26-4e06-aea0-d8bf6031e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=0.00)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff667bc3-f56a-4cc0-aea3-049a9aa6c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training | f1-score | accuracy |  loss \t \t        Val | f1-score | accuracy | precision | recall |  loss\n",
      "         0 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/405 [00:00<?, ?it/s]/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:48<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2227 |   0.2292 | 1.0273 \t \t          0 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:09<00:00, 14.07it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2900 |   0.3055 |    0.2814 | 0.3055 | 0.8368\n",
      "         1 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:48<00:00,  8.35it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2569 |   0.6733 | 0.8169 \t \t          1 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:10<00:00, 13.42it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2986 |   0.3053 |    0.2984 | 0.3053 | 0.7729\n",
      "         2 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:48<00:00,  8.42it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2658 |   0.6955 | 0.7674 \t \t          2 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:09<00:00, 13.57it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3068 |   0.3147 |    0.2998 | 0.3147 | 0.7448\n",
      "         3 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:47<00:00,  8.52it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2701 |   0.7062 | 0.7338 \t \t          3 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:09<00:00, 14.14it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3051 |   0.3179 |    0.3013 | 0.3179 | 0.7649\n",
      "         4 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:46<00:00,  8.62it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2737 |   0.7154 | 0.7157 \t \t          4 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:09<00:00, 13.85it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3100 |   0.3226 |    0.3021 | 0.3226 | 0.7377\n",
      "         5 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:48<00:00,  8.36it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2838 |   0.8350 | 0.6943 \t \t          5 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:09<00:00, 13.84it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3088 |   0.3151 |    0.3056 | 0.3151 | 0.7191\n",
      "         6 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:47<00:00,  8.45it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2988 |   0.7678 | 0.6719 \t \t          6 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:09<00:00, 13.85it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3124 |   0.3170 |    0.3096 | 0.3170 | 0.7107\n",
      "         7 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:47<00:00,  8.47it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3106 |   0.7722 | 0.6538 \t \t          7 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:09<00:00, 13.53it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3380 |   0.3354 |    0.4491 | 0.3354 | 0.7019\n",
      "         8 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:48<00:00,  8.43it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3243 |   0.7455 | 0.6371 \t \t          8 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:10<00:00, 12.87it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3310 |   0.3284 |    0.4526 | 0.3284 | 0.6970\n",
      "         9 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 405/405 [00:47<00:00,  8.48it/s]\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3328 |   0.8296 | 0.6148 \t \t          9 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 135/135 [00:10<00:00, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.3381 |   0.3369 |    0.3934 | 0.3369 | 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1e20\n",
    "print('{:>10} | {:>8} | {:>8} | {:>5} \\t \\t {:>10} | {:>8} | {:>8} | {:>9} | {:>6} | {:>5}'.format(\n",
    "    \"Training\", \"f1-score\", \"accuracy\", \"loss\", \"Val\", \"f1-score\", \"accuracy\", \"precision\", \"recall\", \"loss\"))\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    print(f\"{epoch:>10} |\", end=' ')\n",
    "    train_step(model, train_loader, criterion, optimizer)\n",
    "    print(f\"{epoch:>10} |\", end=' ')\n",
    "    \n",
    "    acc, loss = evaluate(model, val_loader, criterion)\n",
    "    \n",
    "    if (loss < best_loss):\n",
    "        best_loss = loss\n",
    "        #torch.save(model, 'current_best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac41fb-0f1f-46f3-8182-03fa9bbc6a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
