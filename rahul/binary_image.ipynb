{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab1b939-9eb5-434f-b848-734eb54625a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56583435-80f9-43ff-ae1e-5cda563f8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/rasteiger/datasets/hack4good/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6784962b-e15b-4503-8d8b-b414e0500400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataloader classs for images with corresponding labels such that pytorch can work with the data\n",
    "class CustomImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, csv_file, label_name, join_name, class_to_idx, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.label_name = label_name\n",
    "        self.join_name = join_name # column used to join img_dir and csv_file\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        # Integer class mapping: Label classes -> [0, 1, ..., num(labels) - 1] for pytorch\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv_file.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, self.csv_file.iloc[idx][self.join_name])\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        # Load Label\n",
    "        label = self.class_to_idx[self.csv_file.iloc[idx][self.label_name]]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "    def get_class_weights(self):\n",
    "        y_vals = self.csv_file[self.label_name].apply(lambda x: self.class_to_idx[x])\n",
    "        cw = class_weight.compute_class_weight('balanced', classes=y_vals.unique(), y=y_vals).astype(np.float32)\n",
    "        return torch.tensor(cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e5c24b-62b8-4b87-adf5-2f6f48bfc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = data_path + \"images\"\n",
    "csv_path = data_path + \"labels.csv\"\n",
    "\n",
    "csv_file = pd.read_csv(csv_path)\n",
    "csv_file['is_damage'] = (csv_file['extent'] >= 20).astype(int)\n",
    "\n",
    "label_name = 'is_damage'\n",
    "join_name = 'filename'\n",
    "class_to_idx = {v:i for i, v in enumerate(csv_file[label_name].unique())} \n",
    "num_classes = len(list(class_to_idx.values()))\n",
    "size = 224\n",
    "\n",
    "# Perform image augmentation while training to artificially inflate dataset\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(size=(size, size), scale=(0.8, 1.0)),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.95),#, contrast=None, saturation=None),\n",
    "    torchvision.transforms.RandomRotation(degrees = (-15,+15)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Only resize for validation and test images\n",
    "val_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((size, size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Data split across farmers\n",
    "# roughly 60% Train 20% Validate 20% Test split: https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "farmer_split = pd.Series(csv_file['farmer_id'].unique())\n",
    "train_f, val_f, test_f = np.split(farmer_split.sample(frac=1), [int(.6*len(farmer_split)), int(.8*len(farmer_split))])\n",
    "\n",
    "train_csv = csv_file[csv_file['farmer_id'].isin(train_f)]\n",
    "val_csv = csv_file[csv_file['farmer_id'].isin(val_f)]\n",
    "test_csv = csv_file[csv_file['farmer_id'].isin(test_f)]\n",
    "\n",
    "train_dataset = CustomImageDataset(img_dir=img_dir, csv_file=train_csv, label_name=label_name, join_name=join_name, transform=train_transforms, class_to_idx=class_to_idx)\n",
    "val_dataset = CustomImageDataset(img_dir=img_dir, csv_file=val_csv, label_name=label_name, join_name=join_name, transform=val_transforms, class_to_idx=class_to_idx)\n",
    "test_dataset = CustomImageDataset(img_dir=img_dir, csv_file=test_csv, label_name=label_name, join_name=join_name, transform=val_transforms, class_to_idx=class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc8c20c-3d42-4787-bdc0-124aa31f61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=64)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c69b5a0-0f64-4df0-a896-78ea368cd698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ConvNeXt(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
       "        )\n",
       "        (3): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
       "        )\n",
       "        (4): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
       "        )\n",
       "        (5): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
       "        )\n",
       "        (6): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
       "        )\n",
       "        (7): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
       "        )\n",
       "        (8): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (4): GELU(approximate='none')\n",
       "            (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.convnext_tiny(weights='DEFAULT')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.classifier[2] = torch.nn.Linear(768, num_classes, bias=True) # Since, we have only two classes, change the last layer\n",
    "model = torch.nn.DataParallel(model) # Ensure that we use all gpus available\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "124d5f6b-860e-4273-bb09-ebb0e5d9d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, data_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    tot_loss = 0\n",
    "    pred_labels, true_labels = [], []\n",
    "    \n",
    "    for i, (img, label) in enumerate(tqdm(train_loader)):\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(img)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        \n",
    "        pred_labels.append(pred.detach().cpu().numpy())\n",
    "        true_labels.append(label.detach().cpu().numpy())\n",
    "        \n",
    "        tot_loss += loss\n",
    "    \n",
    "    all_pred = np.concatenate(pred_labels)\n",
    "    all_true = np.concatenate(true_labels)\n",
    "    \n",
    "    f1 = f1_score(all_pred, all_true, average='macro')\n",
    "    accuracy = balanced_accuracy_score(all_pred, all_true)\n",
    "    tot_loss /= len(data_loader)\n",
    "\n",
    "    print(f\"{epoch:>10} |\", end=' ')\n",
    "    line = '{:>8.4f} | {:>8.4f} | {:>5.4f}'.format(f1, accuracy, tot_loss.detach().cpu().numpy())\n",
    "    print(line, end=' \\t \\t ')\n",
    "    \n",
    "    return accuracy, tot_loss\n",
    "    \n",
    "def evaluate(model, data_loader, criterion, is_test=False, epoch=0):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    tot_loss = 0\n",
    "    pred_labels, true_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(tqdm(data_loader)):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "       \n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            pred = torch.argmax(output, dim=1)\n",
    "        \n",
    "            pred_labels.append(pred.detach().cpu().numpy())\n",
    "            true_labels.append(label.detach().cpu().numpy())\n",
    "\n",
    "            tot_loss += loss\n",
    "        \n",
    "    all_pred = np.concatenate(pred_labels)\n",
    "    all_true = np.concatenate(true_labels)\n",
    "    \n",
    "    f1 = f1_score(all_true, all_pred, average='macro')\n",
    "    accuracy = balanced_accuracy_score(all_true, all_pred)\n",
    "    precision = precision_score(all_true, all_pred, average='macro')\n",
    "    recall = recall_score(all_true, all_pred, average='macro')\n",
    "        \n",
    "    tot_loss /= len(data_loader)\n",
    "\n",
    "    if is_test:\n",
    "        cf_matrix = confusion_matrix(all_true, all_pred)\n",
    "        df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [\"Damage\",\"No Damage\"], columns = [\"Damage\",\"No Damage\"])\n",
    "        plt.figure(figsize = (12,7))\n",
    "        sns.heatmap(df_cm, annot=True)\n",
    "\n",
    "    print(f\"{epoch:>10} |\", end=' ')\n",
    "    line = '{:>8.4f} | {:>8.4f} | {:>9.4f} | {:>6.4f} | {:>5.4f}'.format(f1, accuracy, precision, recall, tot_loss.detach().cpu().numpy())\n",
    "    print(line)\n",
    "    \n",
    "    return accuracy, tot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc557f18-f736-4013-ba6e-57faf1ee81f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd52f9c-773d-40f1-a9e4-e7e2e61ff8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=0.00)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=train_dataset.get_class_weights().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5576763a-0482-4349-be17-a5e991b0b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training | f1-score | accuracy |  loss \t \t        Val | f1-score | accuracy | precision | recall |  loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/391 [00:00<?, ?it/s]/home/rasteiger/miniconda3/envs/h4g/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0 |   0.7051 |   0.7027 | 0.5574 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:09<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0 |   0.7500 |   0.7426 |    0.7633 | 0.7426 | 0.5110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1 |   0.7740 |   0.7710 | 0.4637 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:10<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1 |   0.7747 |   0.7762 |    0.7733 | 0.7762 | 0.4773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2 |   0.7920 |   0.7883 | 0.4343 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:10<00:00, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2 |   0.7781 |   0.7807 |    0.7759 | 0.7807 | 0.4653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3 |   0.8043 |   0.8004 | 0.4086 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:10<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3 |   0.7747 |   0.7812 |    0.7706 | 0.7812 | 0.4605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4 |   0.8151 |   0.8109 | 0.3922 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:10<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4 |   0.7780 |   0.7723 |    0.7862 | 0.7723 | 0.4844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:47<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         5 |   0.8259 |   0.8214 | 0.3732 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:11<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         5 |   0.7834 |   0.7832 |    0.7835 | 0.7832 | 0.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         6 |   0.8311 |   0.8267 | 0.3598 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:10<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         6 |   0.7773 |   0.7847 |    0.7730 | 0.7847 | 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7 |   0.8404 |   0.8358 | 0.3434 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:10<00:00, 14.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7 |   0.7778 |   0.7878 |    0.7731 | 0.7878 | 0.4708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         8 |   0.8480 |   0.8434 | 0.3270 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:11<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         8 |   0.7861 |   0.7877 |    0.7845 | 0.7877 | 0.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         9 |   0.8588 |   0.8542 | 0.3156 \t \t "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 153/153 [00:11<00:00, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         9 |   0.7802 |   0.7750 |    0.7876 | 0.7750 | 0.5073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1e20\n",
    "print('{:>10} | {:>8} | {:>8} | {:>5} \\t \\t {:>10} | {:>8} | {:>8} | {:>9} | {:>6} | {:>5}'.format(\n",
    "    \"Training\", \"f1-score\", \"accuracy\", \"loss\", \"Val\", \"f1-score\", \"accuracy\", \"precision\", \"recall\", \"loss\"))\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    train_step(model, train_loader, criterion, optimizer, epoch)    \n",
    "    acc, loss = evaluate(model, val_loader, criterion, epoch=epoch)\n",
    "    \n",
    "    if (loss < best_loss):\n",
    "        best_loss = loss\n",
    "        #torch.save(model, 'current_best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87302b17-3ada-4870-8f9c-a18935137333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score | accuracy | precision | recall |  loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 132/132 [00:10<00:00, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0 |   0.7683 |   0.7622 |    0.7807 | 0.7622 | 0.5236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('{:>8} | {:>8} | {:>9} | {:>6} | {:>5}'.format(\"f1-score\", \"accuracy\", \"precision\", \"recall\", \"loss\"))\n",
    "a, l = evaluate(model, test_loader, criterion, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d5dc544-5ba0-47dd-aaa4-cb47f6f322e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_damage\n",
       "0    13464\n",
       "1     8090\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file['is_damage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbcfbc6-4c86-41fa-a740-fbc98305192a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
